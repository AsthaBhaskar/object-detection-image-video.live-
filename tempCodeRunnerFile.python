from cProfile import label
from turtle import color, width
import cv2
from matplotlib.cbook import flatten
import numpy as np

net = cv2.dnn.readNet('yolov3 (2).weights', 'yolov3 (2).cfg')#net=network

classes = []
with open("coco.names", "r") as f:#extract object name from coco file
    classes = f.read().splitlines()

#print(classes) #output=name of all things it can detect

#load target image
#img = cv2.imread('image5.jpg')
#img = cv2.resize(img, (700, 640))

#video
cap = cv2.VideoCapture(0)


while True:
    _, img = cap.read()

    height, width, _ = img.shape


    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)

    #shows 3 BW images of given size and pixels
    #for b in blob:
    #   for n, img_blob in enumerate(b):
    #       cv2.imshow(str(n), img_blob)


    net.setInput(blob)#to set input from blob to network
    output_layers_names = net.getUnconnectedOutLayersNames()#to get layer names
    layersOutputs = net.forward(output_layers_names)#to get output from output layers

    boxes = []
    confidences = []#how likely box contains objects and prob of prediction
    class_ids = []

    for output in layersOutputs:#to extract output
        for detection in output:#to extract information from the output
            scores = detection[5:]#used to store all the class prediction
            class_id = np.argmax(scores)#location that stores the higher scores
            confidence = scores[class_id]#higher score into variable
            if confidence > 0.5:
                center_x = int(detection[0]*width)
                center_y = int(detection[1]*height)
                w = int(detection[2]*width)
                h = int(detection[3]*height)

                x = int(center_x - w/2)
                y = int(center_y - h/2)


                boxes.append([x,y,w,h])
                confidences.append((float(confidence)))
                class_ids.append(class_id)

    print(len(boxes))#to get number of objs that can be detected
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)#last is max suppression
    if len(indexes)>0:
        print(indexes.flatten())#prints obj number that can be detected and missing values have redundances

    font = cv2.FONT_HERSHEY_PLAIN
    colors = np.random.uniform(0, 255, size=(len(boxes), 3))#color=0 to 255(color code),size=len of boxes, 3 channels


    if len(indexes)>0:
        for i in indexes.flatten():#to identify each obj detected
            x, y, w, h = boxes[i]#extract info in boxes with location and size of rectangles
            label = str(classes[class_ids[i]])#extract class ids from coco file string as labels
            confidence = str(round(confidences[i],2))#assign confidences to string
            color = colors [i]#color for each object
            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)#coordinates,size,color code,thickness
            cv2.putText(img, label +" "+ confidence, (x,y+20), font, 2, (0,0,0), 2)#location,font,font size 2,white color code font,thickness of font 2


    cv2.imshow('image', img)#shows original image
    key = cv2.waitKey(1)#to break while loop
    if key==27:
        break

cap.release()
cv2.destroyAllWindows()